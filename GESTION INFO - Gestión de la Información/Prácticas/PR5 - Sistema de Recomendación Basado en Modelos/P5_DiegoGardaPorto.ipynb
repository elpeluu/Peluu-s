{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 5: Sistema de Recomendación (Modelos)\n",
        "\n",
        "---\n",
        "\n",
        "* **Autor:** Diego Garda Porto\n",
        "* **Asignatura:** Gestión de la Información\n",
        "* **Grado:** Ingeniería Informática\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Implementar un filtro colaborativo basado en factorización matricial de bajo rango (se puede utilizar el algoritmo SVD de Surprise). Además, realizarán actividades complementarias para profundizar en la interpretación, evaluación y aplicación de los modelos de recomendación.\n",
        "\n",
        "\n",
        "## Instrucciones\n",
        "1. Implementación básica del filtro colaborativo. Utilizar el dataset de ratings\n",
        "de MovieLens de 100k ratings (recommended for education and development, small)\n",
        "2. Añadir uno o varios usuarios que representen a los miembros del equipo de prácticas (con ratings a un subconjunto de las películas del dataset), ajustar el filtro y mostrar las 10 mejores recomendaciones que proporciona a cada usuario añadido.\n",
        "3. Analizar los sesgos estimados en el modelo ¿Qué usuarios tienden a puntuar más bajo o más alto? ¿Qué películas tienden a tener más ratings?\n",
        "4. Análisis en el espacio latente a partir de los vectores de características latentes de usuarios y películas. Calcular las 10 películas más próximas a una dada, por ejemplo, “Toy Story”\n",
        "4. Utilizar alguna técnica de clustering para obtener grupos de usuarios similares que pueden ser interpretados como segmentos de clientes\n",
        "\n"
      ],
      "metadata": {
        "id": "hoo4ECU9LvF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- Instalación de numpy"
      ],
      "metadata": {
        "id": "wPk4rwSoL1H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NT11CmLLJ7hS",
        "outputId": "8369ffc2-de91-4d95-e5a7-e1fd21fef050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a811a1a1e3334855804b01f531353df6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- Importación de paquetes\n",
        "\n",
        "Antes de hacer esto hay que reiniciar la sesión tras la instalación anterior de numpy"
      ],
      "metadata": {
        "id": "xe0tRf0TMBZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Ejecutar después de reiniciar la sesión)\n",
        "\n",
        "# 1. Instalar scikit-surprise\n",
        "!pip install scikit-surprise\n",
        "\n",
        "# 2. Importaciones de Python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "\n",
        "# 3. Importaciones de Surprise\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# 4. Importaciones de Scikit-learn y SciPy (para Tareas 4 y 5)\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cosine # Para similitud\n",
        "\n",
        "# 5. Importaciones de Visualización (Opcional pero recomendado)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Configuración\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Librerías instaladas e importadas correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9aaFP7aLYGI",
        "outputId": "1acc1197-d0cf-458b-c2a6-d67548d0a167",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2555157 sha256=e59c1fa7b83a354824913c12b4eac7ca3c94db95a9e5ba9603ec9d8c55a3f7ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Librerías instaladas e importadas correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BY6J6CMdNK-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3- Carga de datos (ml-100k) y construcción del Trainset\n",
        "\n",
        "He utilizado el Dataset de internet MovieLens 100k que tiene 100.000 datos porque con el otro estaba teniendo problemas al cargarlo con la RAM del programa al ser un archivo más grande."
      ],
      "metadata": {
        "id": "CD73BUooNMOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargar el Dataset (MovieLens 100k)\n",
        "try:\n",
        "    datos = Dataset.load_builtin('ml-100k')\n",
        "    print(\"Dataset MovieLens 100k cargado\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR - No se pudo descargar el dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# 2. Construir el Trainset completo (para el modelo base)\n",
        "trainset_base = datos.build_full_trainset()\n",
        "print(f\"\\nDatos del Trainset Base:\")\n",
        "print(f\"Número de usuarios: {trainset_base.n_users}\")\n",
        "print(f\"Número de películas: {trainset_base.n_items}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si_ersDKNWyy",
        "outputId": "38d01e8c-b990-4300-cba3-c7f66837b698"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Dataset MovieLens 100k cargado\n",
            "\n",
            "Datos del Trainset Base:\n",
            "Número de usuarios: 943\n",
            "Número de películas: 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4- Recoger datos de las películas"
      ],
      "metadata": {
        "id": "6ja_WXJcOCb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Función para obtener los títulos de las películas y guardarlas\n",
        "def get_movie_titles():\n",
        "    try:\n",
        "        home_dir = os.path.expanduser('~')\n",
        "        ruta = os.path.join(\n",
        "            home_dir,\n",
        "            '.surprise_data',\n",
        "            'ml-100k',\n",
        "            'ml-100k',\n",
        "            'u.item'\n",
        "        )\n",
        "\n",
        "        tirulos_peliculas = {}\n",
        "        # Abrimos el archivo con la codificación correcta\n",
        "        with open(ruta, 'r', encoding='ISO-8859-1') as f:\n",
        "            for line in f:\n",
        "                parts = line.split('|')\n",
        "                id_pelicula = parts[0]\n",
        "                titulo = parts[1]\n",
        "                tirulos_peliculas[id_pelicula] = titulo\n",
        "\n",
        "        return tirulos_peliculas\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: No se encontró 'u.item' en {ruta}\")\n",
        "        print(\"Asegúrate de que 'Dataset.load_builtin' se ejecutó correctamente.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error en get_movie_titles: {e}\")\n",
        "        return None\n",
        "\n",
        "# 2. Crear el diccionario de títulos\n",
        "tirulos_peliculas = get_movie_titles()\n",
        "\n",
        "# 3. Mostrar ejemplos\n",
        "if tirulos_peliculas:\n",
        "    print(\"Diccionario de títulos creado con éxito.\")\n",
        "    print(f\"Ejemplo -> ID 1: {tirulos_peliculas.get('1')}\")\n",
        "    print(f\"Ejemplo -> ID 50: {tirulos_peliculas.get('50')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2XnSl3kOIRw",
        "outputId": "95e0e6ea-62a1-4c92-c33d-093eca14c482"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario de títulos creado con éxito.\n",
            "Ejemplo -> ID 1: Toy Story (1995)\n",
            "Ejemplo -> ID 50: Star Wars (1977)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5- Entrenar el modelo SVD con los datos"
      ],
      "metadata": {
        "id": "lTXs9ZZ7OpHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar SVD\n",
        "algoritmo_svd = SVD(n_factors=50,\n",
        "                    n_epochs=20,\n",
        "                    random_state=42)\n",
        "\n",
        "# Entrenar el modelo con el trainset base\n",
        "algoritmo_svd.fit(trainset_base)\n",
        "\n",
        "print(\"Modelo SVD base entrenado con éxito.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CQEmhlJOt1u",
        "outputId": "7aa7e1dd-8341-47d8-b5e9-f20cf1edf33c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo SVD base entrenado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6- Añadir valoraciones de nuevos usuarios"
      ],
      "metadata": {
        "id": "7_PTaveZTci1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los datos de surprise a un DataFrame de Pandas\n",
        "ratings_df = pd.DataFrame(datos.raw_ratings, columns=['uid', 'iid', 'rating', 'timestamp'])\n",
        "\n",
        "# Creación de nuevos ratings para 2 nuevos usuarios\n",
        "nuevos_ratings = [\n",
        "    # Ratings Usuario 1 = diego\n",
        "    ('diego', '50', 5.0, 0),  # 50: Star Wars\n",
        "    ('diego', '181', 5.0, 0), # 181: Return of the Jedi\n",
        "    ('diego', '1', 1.0, 0),   # 1: Toy Story (no le gustó)\n",
        "    ('diego', '210', 4.0, 0), # 210: Indiana Jones: En busca del arca perdida\n",
        "    ('diego', '269', 5.0, 0), # 269: Men in Black\n",
        "\n",
        "    # Ratings Usuario 2\n",
        "    ('manuel', '1', 5.0, 0),   # 1: Toy Story\n",
        "    ('manuel', '7', 4.0, 0),   # 7: Twelve Monkeys\n",
        "    ('manuel', '127', 5.0, 0), # 127: Godfather, The\n",
        "    ('manuel', '56', 4.0, 0),  # 56: Pulp Fiction\n",
        "    ('manuel', '95', 5.0, 0),  # 95: Aladdin\n",
        "]\n",
        "\n",
        "# Lista de los nuevos usuarios\n",
        "nuevos_usuarios = ['diego', 'manuel']\n",
        "\n",
        "# Convertir a DataFrame y añadir al original\n",
        "nuevos_ratings_df = pd.DataFrame(nuevos_ratings, columns=['uid', 'iid', 'rating', 'timestamp'])\n",
        "ratings_completos_df = pd.concat([ratings_df, nuevos_ratings_df], ignore_index=True)\n",
        "\n",
        "print(f\"Ratings originales: {len(ratings_df)}\")\n",
        "print(f\"Ratings nuevos añadidos: {len(nuevos_ratings_df)}\")\n",
        "print(f\"Total ratings (con equipo): {len(ratings_completos_df)}\")\n",
        "\n",
        "# Mostrar los ratings que hemos añadido\n",
        "print(\"\\nRatings añadidos por el equipo:\")\n",
        "print(nuevos_ratings_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFTMua9gTjHi",
        "outputId": "1b45ef94-1742-4ba4-8ed0-c957817c9c04",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings originales: 100000\n",
            "Ratings nuevos añadidos: 10\n",
            "Total ratings (con equipo): 100010\n",
            "\n",
            "Ratings añadidos por el equipo:\n",
            "      uid  iid  rating  timestamp\n",
            "0   diego   50     5.0          0\n",
            "1   diego  181     5.0          0\n",
            "2   diego    1     1.0          0\n",
            "3   diego  210     4.0          0\n",
            "4   diego  269     5.0          0\n",
            "5  manuel    1     5.0          0\n",
            "6  manuel    7     4.0          0\n",
            "7  manuel  127     5.0          0\n",
            "8  manuel   56     4.0          0\n",
            "9  manuel   95     5.0          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7- Reentrenar al modelo con los nuevos ratings añadidos"
      ],
      "metadata": {
        "id": "1102ev3OWL7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el nuevo dataset\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "datos_nuevo = Dataset.load_from_df(ratings_completos_df[['uid', 'iid', 'rating']], reader)\n",
        "\n",
        "# Construir trainset nuevo con los nuevos usuarios\n",
        "trainset_nuevo = datos_nuevo.build_full_trainset()\n",
        "print(\"\\nNuevo Trainset con usuarios añadidos:\")\n",
        "print(f\"Usuarios (nuevo): {trainset_nuevo.n_users}\")\n",
        "print(f\"Películas (nuevo): {trainset_nuevo.n_items}\")\n",
        "\n",
        "# Reentrenar el modelo\n",
        "print(\"\\nReentrenando modelo con nuevos usuarios\")\n",
        "algoritmo_svd_nuevo = SVD(n_factors=50, n_epochs=20, random_state=42)\n",
        "algoritmo_svd_nuevo.fit(trainset_nuevo)\n",
        "print(\"Modelo re-entrenado con éxito.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UHDH7X-WQZz",
        "outputId": "2ccedeb4-48fd-440d-ff21-fe6e24574b5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nuevo Trainset con usuarios añadidos:\n",
            "Usuarios (nuevo): 945\n",
            "Películas (nuevo): 1682\n",
            "\n",
            "Reentrenando modelo con nuevos usuarios\n",
            "Modelo re-entrenado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8- Generar recomendaciones para los nuevos usuarios añadidos"
      ],
      "metadata": {
        "id": "rnMMu2O4W1Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que genera recomendaciones\n",
        "def generar_recomendaciones(algoritmo, iduser, n=10):\n",
        "\n",
        "    # Obtener el id del usuario\n",
        "    try:\n",
        "        id_usuario = algoritmo.trainset.to_inner_uid(user)\n",
        "    except ValueError:\n",
        "        print(f\"Error: El usuario {id_usuario} no se encontró en el trainset.\")\n",
        "        return []\n",
        "\n",
        "    # Obtener los id de las películas valoradas por el usario\n",
        "    peliculas_valoradas = set(\n",
        "        iid for (iid, rating) in algoritmo.trainset.ur[id_usuario]\n",
        "    )\n",
        "\n",
        "    # Predecir el rating para las películas que no ha puntuado\n",
        "    predicciones = []\n",
        "    for item_inner_id in algoritmo.trainset.all_items():\n",
        "        if item_inner_id not in peliculas_valoradas:\n",
        "            # Convertir ID interno de película a ID bruto (string)\n",
        "            item_raw_id = algoritmo.trainset.to_raw_iid(item_inner_id)\n",
        "            # Predecir rating\n",
        "            pred = algoritmo.predict(uid=iduser, iid=item_raw_id)\n",
        "            predicciones.append((item_raw_id, pred.est))\n",
        "\n",
        "    # 4. Ordenar por rating estimado (descendente)\n",
        "    predicciones.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # 5. Devolver las Top-N (traducidas a títulos)\n",
        "    top_n_with_titles = []\n",
        "    for (raw_id, estimated_rating) in predicciones[:n]:\n",
        "        # Usamos nuestro diccionario 'movie_titles' para traducir\n",
        "        title = tirulos_peliculas.get(raw_id, \"Título Desconocido\")\n",
        "        top_n_with_titles.append((title, estimated_rating))\n",
        "\n",
        "    return top_n_with_titles\n",
        "\n",
        "# --- Aquí es donde se \"muestran\" las recomendaciones ---\n",
        "print(\"\\n--- RECOMENDACIONES TOP-10 PARA EL EQUIPO ---\")\n",
        "\n",
        "# (La variable 'usuarios_equipo' la definimos en la Celda 12)\n",
        "for user in nuevos_usuarios:\n",
        "    print(f\"\\n--- Recomendaciones para {user} ---\")\n",
        "    recomendaciones = generar_recomendaciones(algoritmo_svd_nuevo, user, n=10)\n",
        "\n",
        "    if recomendaciones:\n",
        "        for i, (title, rating) in enumerate(recomendaciones):\n",
        "            # Imprime: \" 1. Titulo de Pelicula (Rating est: 4.52)\"\n",
        "            print(f\"{i+1:2}. {title} (Rating est: {rating:.2f})\")\n",
        "    else:\n",
        "        print(\"No se pudieron generar recomendaciones.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmJrBXhNW6WI",
        "outputId": "a9dd0e4a-8641-47b6-c9f3-f4a81a5b2444"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RECOMENDACIONES TOP-10 PARA EL EQUIPO ---\n",
            "\n",
            "--- Recomendaciones para diego ---\n",
            " 1. Close Shave, A (1995) (Rating est: 4.65)\n",
            " 2. Rear Window (1954) (Rating est: 4.64)\n",
            " 3. Godfather, The (1972) (Rating est: 4.63)\n",
            " 4. Shawshank Redemption, The (1994) (Rating est: 4.59)\n",
            " 5. One Flew Over the Cuckoo's Nest (1975) (Rating est: 4.54)\n",
            " 6. Raiders of the Lost Ark (1981) (Rating est: 4.50)\n",
            " 7. Usual Suspects, The (1995) (Rating est: 4.50)\n",
            " 8. Empire Strikes Back, The (1980) (Rating est: 4.48)\n",
            " 9. Casablanca (1942) (Rating est: 4.45)\n",
            "10. North by Northwest (1959) (Rating est: 4.44)\n",
            "\n",
            "--- Recomendaciones para manuel ---\n",
            " 1. Close Shave, A (1995) (Rating est: 4.92)\n",
            " 2. Raiders of the Lost Ark (1981) (Rating est: 4.87)\n",
            " 3. North by Northwest (1959) (Rating est: 4.86)\n",
            " 4. Wrong Trousers, The (1993) (Rating est: 4.85)\n",
            " 5. Star Wars (1977) (Rating est: 4.81)\n",
            " 6. Rear Window (1954) (Rating est: 4.78)\n",
            " 7. Shawshank Redemption, The (1994) (Rating est: 4.78)\n",
            " 8. 12 Angry Men (1957) (Rating est: 4.75)\n",
            " 9. Casablanca (1942) (Rating est: 4.72)\n",
            "10. Godfather: Part II, The (1974) (Rating est: 4.71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yW9nOfjX-PB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9- Análisis de sesgos (Usuarios y Películas)\n",
        "\n",
        "\n",
        "*   Usuarios que tienden a puntuar más alto y mas bajo\n",
        "*   Películas que tienden a tener más ratingsd\n",
        "\n"
      ],
      "metadata": {
        "id": "jtkpCsWi-TKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ANÁLISIS DE SESGOS\")\n",
        "\n",
        "# Extraer biases sesgos del modelo (usuarios y películas)\n",
        "sUsuarios = algoritmo_svd_nuevo.bu\n",
        "sPeliculas = algoritmo_svd_nuevo.bi\n",
        "\n",
        "print(\"\\nSESGOS DE LOS USUARIOS\")\n",
        "# ANALIZAR SESGOS DE USUARIOS\n",
        "lista_sUsuarios = []\n",
        "for inner_id in range(trainset_nuevo.n_users):\n",
        "    # Extraer el id del usuario\n",
        "    raw_id = trainset_nuevo.to_raw_uid(inner_id)\n",
        "    # Extraer el sesgo del usuario\n",
        "    bias = sUsuarios[inner_id]\n",
        "    # Guardar la información en la lista\n",
        "    lista_sUsuarios.append((raw_id, bias))\n",
        "\n",
        "sUsuarios_df = pd.DataFrame(lista_sUsuarios, columns=['Usuario', 'Sesgo (bias)'])\n",
        "sUsuarios_df = sUsuarios_df.sort_values(by='Sesgo (bias)')\n",
        "\n",
        "# Mostrar resultados para los usuarios\n",
        "print(\"\\n1. Usuarios que tienden a puntuar más bajo:\")\n",
        "print(sUsuarios_df.head(5).to_string(index=False))\n",
        "print(\"\\n2. Usuarios que tienden a puntuar más alto:\")\n",
        "print(sUsuarios_df.tail(5).sort_values(by='Sesgo (bias)', ascending=False).to_string(index=False))\n",
        "\n",
        "print(\"\\nSESGOS DE LAS PELÍCULAS\")\n",
        "# ANALIZAR SESGOS DE PELÍCULAS\n",
        "lista_sPeliculas = []\n",
        "for inner_id in range(trainset_nuevo.n_items):\n",
        "    raw_id = trainset_nuevo.to_raw_iid(inner_id)\n",
        "    # Usamos nuestro diccionario: tirulos_peliculas\n",
        "    title = tirulos_peliculas.get(raw_id, \"N/A\")\n",
        "    bias = sPeliculas[inner_id]\n",
        "    lista_sPeliculas.append((raw_id, title, bias))\n",
        "\n",
        "sPeliculas_df = pd.DataFrame(lista_sPeliculas, columns=['ID', 'Película', 'Sesgo (bias)'])\n",
        "sPeliculas_df = sPeliculas_df.sort_values(by='Sesgo (bias)')\n",
        "\n",
        "# Mostrar los resultados para las películas\n",
        "print(\"\\n3. Películas que tienden a recibir puntuaciones más bajas:\")\n",
        "print(sPeliculas_df[['Película', 'Sesgo (bias)']].head(5).to_string(index=False))\n",
        "print(\"\\n4. Películas que tienden a recibir puntuaciones más altas:\")\n",
        "print(sPeliculas_df[['Película', 'Sesgo (bias)']].tail(5).sort_values(by='Sesgo (bias)', ascending=False).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5iIjxA5-nxc",
        "outputId": "8ffc1aa8-ef25-46f4-b147-e022c3af223e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANÁLISIS DE SESGOS\n",
            "\n",
            "SESGOS DE LOS USUARIOS\n",
            "\n",
            "1. Usuarios que tienden a puntuar más bajo:\n",
            "Usuario  Sesgo (bias)\n",
            "    181     -1.765430\n",
            "    405     -1.657426\n",
            "    445     -1.596894\n",
            "    774     -1.422383\n",
            "    206     -1.317713\n",
            "\n",
            "2. Usuarios que tienden a puntuar más alto:\n",
            "Usuario  Sesgo (bias)\n",
            "    688      1.324319\n",
            "    507      1.170552\n",
            "    427      1.076162\n",
            "    849      1.000384\n",
            "    907      0.965699\n",
            "\n",
            "SESGOS DE LAS PELÍCULAS\n",
            "\n",
            "3. Películas que tienden a recibir puntuaciones más bajas:\n",
            "                                  Película  Sesgo (bias)\n",
            "Children of the Corn: The Gathering (1996)     -1.519936\n",
            "                           Bio-Dome (1996)     -1.410702\n",
            "        Mortal Kombat: Annihilation (1997)     -1.404321\n",
            " Lawnmower Man 2: Beyond Cyberspace (1996)     -1.399988\n",
            "           Free Willy 3: The Rescue (1997)     -1.380572\n",
            "\n",
            "4. Películas que tienden a recibir puntuaciones más altas:\n",
            "                        Película  Sesgo (bias)\n",
            "           Close Shave, A (1995)      1.083916\n",
            "      Wrong Trousers, The (1993)      1.076726\n",
            "         Schindler's List (1993)      1.032572\n",
            "Shawshank Redemption, The (1994)      1.020061\n",
            "               Casablanca (1942)      1.016083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10- Análisis del Espacio Latente\n",
        "\n",
        "Calculo de las 10 películas más cercanas a una dada."
      ],
      "metadata": {
        "id": "qC9CZHO4Ib4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TOP 10 PELÍCULAS MÁS SIMILARES A PULP FICTION (1994)\")\n",
        "\n",
        "# Película sobre la que trabajar\n",
        "pelicula_objetivo = \"Pulp Fiction (1994)\"\n",
        "\n",
        "# Encontrar ID\n",
        "id_bruto_objetivo = None\n",
        "# Recorremos diccionario de titulos para encontrar el ID\n",
        "for raw_id_temp, title in tirulos_peliculas.items():\n",
        "    if title == pelicula_objetivo:\n",
        "        id_bruto_objetivo = raw_id_temp\n",
        "        break\n",
        "\n",
        "if id_bruto_objetivo is None:\n",
        "    print(f\"Error: No se pudo encontrar '{pelicula_objetivo}' en el diccionario.\")\n",
        "else:\n",
        "    print(f\"Película objetivo encontrada: {pelicula_objetivo} con ID: {id_bruto_objetivo})\")\n",
        "\n",
        "    # 3. Obtener el ID interno (inner_id)\n",
        "    id_interno_objetivo = trainset_nuevo.to_inner_iid(id_bruto_objetivo)\n",
        "\n",
        "    # 4. Obtener el vector latente (de la matriz 'qi' del modelo)\n",
        "    vector_peliculas = algoritmo_svd_nuevo.qi\n",
        "    vector_objetivo = vector_peliculas[id_interno_objetivo]\n",
        "\n",
        "    # 5. Calcular similitud con todas las demás películas\n",
        "    similitudes = []\n",
        "    for inner_id_actual in range(trainset_nuevo.n_items):\n",
        "\n",
        "        # Saltamos si se ha encontrado la misma película (Pulp Fiction)\n",
        "        if inner_id_actual == id_interno_objetivo:\n",
        "            continue\n",
        "\n",
        "        vector = vector_peliculas[inner_id_actual]\n",
        "\n",
        "        # Calcular similitud: 1 - distancia coseno.\n",
        "        similitud = 1 - cosine(vector_objetivo, vector)\n",
        "\n",
        "        # Traducir ID interno actual a ID bruto para el resultado\n",
        "        raw_id_actual = trainset_nuevo.to_raw_iid(inner_id_actual)\n",
        "        titulo = tirulos_peliculas.get(raw_id_actual, \"N/A\")\n",
        "        similitudes.append((titulo, similitud))\n",
        "\n",
        "    # 6. Ordenar por similitud (descendente)\n",
        "    similitudes.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # 7. Mostrar Top 10\n",
        "    print(f\"\\n10 películas más similares a '{pelicula_objetivo}':\")\n",
        "    for i, (titulo, sim) in enumerate(similitudes[:10]):\n",
        "        print(f\"{i+1:2}. {titulo} (Similitud: {sim:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_rqFUpzIhco",
        "outputId": "e612af17-e849-4a16-a639-bfb53d16b4ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOP 10 PELÍCULAS MÁS SIMILARES A PULP FICTION (1994)\n",
            "Película objetivo encontrada: Pulp Fiction (1994) con ID: 56)\n",
            "\n",
            "10 películas más similares a 'Pulp Fiction (1994)':\n",
            " 1. Cable Guy, The (1996) (Similitud: 0.529)\n",
            " 2. GoodFellas (1990) (Similitud: 0.528)\n",
            " 3. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) (Similitud: 0.513)\n",
            " 4. Casino (1995) (Similitud: 0.469)\n",
            " 5. Mighty Aphrodite (1995) (Similitud: 0.438)\n",
            " 6. Chungking Express (1994) (Similitud: 0.433)\n",
            " 7. Kingpin (1996) (Similitud: 0.426)\n",
            " 8. Henry V (1989) (Similitud: 0.414)\n",
            " 9. Smilla's Sense of Snow (1997) (Similitud: 0.405)\n",
            "10. Talking About Sex (1994) (Similitud: 0.405)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11- Clustering de Usuarios\n",
        "\n",
        "Obtención de grupos de usuarios similares basándonos en la proximidad geométrica de los perfiles según sus características."
      ],
      "metadata": {
        "id": "o18UrQ0pPRE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CLUSTERING DE USUARIOS\")\n",
        "\n",
        "# Obtener la matriz de factores latentes de usuario (pu)\n",
        "vector_usuarios = algoritmo_svd_nuevo.pu\n",
        "\n",
        "# Número de clusters (K)\n",
        "n_clusters = 5\n",
        "\n",
        "# Aplicar K-Means\n",
        "print(f\"Agrupando {trainset_nuevo.n_users} usuarios en {n_clusters} clusters\")\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(vector_usuarios)\n",
        "\n",
        "# Asignar cada usuario a un cluster\n",
        "asignaciones_cluster = kmeans.labels_\n",
        "\n",
        "# Mapear usuarios (raw_id) a sus clusters\n",
        "user_cluster_map = {}\n",
        "for inner_id in range(trainset_nuevo.n_users):\n",
        "    raw_id = trainset_nuevo.to_raw_uid(inner_id)\n",
        "    cluster = asignaciones_cluster[inner_id]\n",
        "    user_cluster_map[raw_id] = cluster\n",
        "\n",
        "# Convertir a DataFrame para análisis\n",
        "cluster_df = pd.DataFrame(user_cluster_map.items(), columns=['Usuario', 'Cluster'])\n",
        "\n",
        "# RESULTADOS\n",
        "print(\"RESULTADOS DEL CLUSTERING\")\n",
        "# Tamaño de cada cluster\n",
        "print(\"1. Tamaño de cada cluster:\")\n",
        "print(cluster_df['Cluster'].value_counts().sort_index().to_string())\n",
        "\n",
        "# Cluster de los usuarios agregados\n",
        "print(\"\\n2. Cluster de los usuarios agregados:\")\n",
        "for user in nuevos_usuarios:\n",
        "    try:\n",
        "        cluster = cluster_df[cluster_df['Usuario'] == user]['Cluster'].values[0]\n",
        "        print(f\"El usuario '{user}' pertenece al Cluster {cluster}\")\n",
        "    except IndexError:\n",
        "        print(f\"Error: No se encontró el cluster para el usuario '{user}'\")"
      ],
      "metadata": {
        "id": "iPcohh3gPdPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b41c151-7f69-4db4-ddfb-4bcfa9b00ae4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLUSTERING DE USUARIOS\n",
            "Agrupando 945 usuarios en 5 clusters\n",
            "RESULTADOS DEL CLUSTERING\n",
            "1. Tamaño de cada cluster:\n",
            "Cluster\n",
            "0    100\n",
            "1    233\n",
            "2    224\n",
            "3    236\n",
            "4    152\n",
            "\n",
            "2. Cluster de los usuarios agregados:\n",
            "El usuario 'diego' pertenece al Cluster 2\n",
            "El usuario 'manuel' pertenece al Cluster 3\n"
          ]
        }
      ]
    }
  ]
}